{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Analysis w session OHE and Class Experts approach w GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import sys\n",
    "#sys.path.insert(0,\"/Library/Python/2.7/site-packages/\") \n",
    "#sys.path.insert(0,\"/Library/Frameworks/Python.framework/Versions/2.7/bin\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/df_all_inc_sess.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get X and y\n",
    "X = data[0:213466]\n",
    "y = pd.read_csv(\"./data/y.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop user_id\n",
    "X = X.drop(['user_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for users w/out session info, set relevant features to -1.\n",
    "X.fillna(value=-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(213466, 764)\n",
      "(213466, 1)\n"
     ]
    }
   ],
   "source": [
    "print X.shape\n",
    "print y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NDF', 'US', 'other', 'FR', 'CA', 'GB', 'ES', 'IT', 'PT', 'NL',\n",
       "       'DE', 'AU'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.country_destination.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y is indexed by dict:\n",
      "{'FR': 1, 'NL': 0, 'PT': 0, 'CA': 0, 'DE': 0, 'IT': 0, 'US': 0, 'NDF': 0, 'other': 0, 'AU': 0, 'GB': 0, 'ES': 0}\n"
     ]
    }
   ],
   "source": [
    "# encode y values SO THAT y has value 1 for the \"single_class\" and value 0 for all other classes..\n",
    "y_labels = {}\n",
    "single_class = \"FR\"\n",
    "i = 1\n",
    "for value in y.country_destination.unique():\n",
    "    if value not in y_labels.keys():\n",
    "        if value == single_class:\n",
    "            y_labels[value] = 1\n",
    "        else:\n",
    "            y_labels[value] = 0\n",
    "    if value == single_class:\n",
    "        y[y == value] = 1\n",
    "    else:\n",
    "        y[y == value] = 0\n",
    "\n",
    "print \"y is indexed by dict:\\n%s\" % y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set y to array-like type\n",
    "y = y.country_destination\n",
    "y.ravel().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train / test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149426, 764)\n",
      "(149426,)\n",
      "(64040, 764)\n",
      "(64040,)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print y_train.shape\n",
    "print X_test.shape\n",
    "print y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting\n",
    "## for \"NDF\", n_estimators=100, max_depth=3 => Acc=0.7184 BUT, # correctly classified NDFs are 30335, it was 32051 when all classes were classified together!!!\n",
    "## for \"FR\", n_estimators=100, max_depth=3 => Acc=0.9763"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.2224           25.94m\n",
      "         2           0.2214           27.91m\n",
      "         3           0.2207           27.48m\n",
      "         4           0.2200           26.57m\n",
      "         5           0.2195           25.94m\n",
      "         6           0.2190           25.34m\n",
      "         7           0.2186           24.64m\n",
      "         8           0.2181           24.24m\n",
      "         9           0.2177           23.51m\n",
      "        10           0.2173           23.12m\n",
      "        20           0.2146           19.46m\n",
      "        30           0.2125           16.31m\n",
      "        40           0.2111           13.87m\n",
      "        50           0.2101           11.38m\n",
      "        60           0.2092            9.03m\n",
      "        70           0.2081            6.77m\n",
      "        80           0.2074            4.56m\n",
      "        90           0.2068            2.28m\n",
      "       100           0.2062            0.00s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbc = GradientBoostingClassifier(n_estimators=100, verbose=1)\n",
    "gbc.fit(X_train, y_train.astype(int))\n",
    "y_pred_gbc = gbc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.976374141162\n"
     ]
    }
   ],
   "source": [
    "print metrics.accuracy_score(y_test.astype(int), y_pred_gbc.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[62524    21]\n",
      " [ 1492     3]]\n",
      "64040\n"
     ]
    }
   ],
   "source": [
    "conf_matrix_gbc = metrics.confusion_matrix(y_test.astype(int), y_pred_gbc.astype(int))\n",
    "print conf_matrix_gbc\n",
    "print sum(sum(conf_matrix_gbc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
